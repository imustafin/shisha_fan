{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Posts and Comments from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEFORE_START = '\\0'\n",
    "AFTER_END = '\\1'\n",
    "def preproc(s):\n",
    "    s = BEFORE_START + s + AFTER_END\n",
    "    s = re.sub(r'\\[.*\\|.*\\]', ' ', s)\n",
    "    s = re.sub(r'[«»]', '\"', s)\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Kalik samples: 1799\n"
     ]
    }
   ],
   "source": [
    "with open('data/kalikfan.json', 'r') as f:\n",
    "    kalikfan = json.load(f)\n",
    "\n",
    "SEQ_LENGTH = 10    \n",
    "\n",
    "texts = []\n",
    "for p in kalikfan:\n",
    "    ptext = p['text'].strip()\n",
    "    if len(ptext) > SEQ_LENGTH:\n",
    "        texts.append(ptext)\n",
    "        \n",
    "    for c in p['comments']:\n",
    "        ctext = c['text'].strip()\n",
    "        if c['likesCount'] > 2 and len(ctext) > SEQ_LENGTH:\n",
    "            texts.append(ctext)\n",
    "\n",
    "texts = [preproc(x) for x in texts]\n",
    "print('Number of Kalik samples:', len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text samples with Soviet: 420\n",
      "Total number of text samples: 2219\n"
     ]
    }
   ],
   "source": [
    "with open('soviet_const.txt', 'r') as f:\n",
    "    sov = f.read()\n",
    "sov = sov.replace('\\n\\n', '\\n ')\n",
    "\n",
    "sov_texts = []\n",
    "for s in sov.split('\\n '):\n",
    "    ss = s.replace('\\n', ' ').strip()\n",
    "    if len(ss) > SEQ_LENGTH:\n",
    "        sov_texts.append(ss)\n",
    "\n",
    "sov_texts = [preproc(x) for x in sov_texts]\n",
    "    \n",
    "print('Number of text samples with Soviet:', len(sov_texts))\n",
    "\n",
    "texts += sov_texts\n",
    "print('Total number of text samples:', len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shisha Learning 🤙🤙🤙\n",
    "From https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text samples: 2219\n",
      "Total vocab: 821\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(texts))))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
    "num_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "input_len = len(texts)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of text samples:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 357397\n"
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for text in texts:\n",
    "    t = [BEFORE_START] * (SEQ_LENGTH - 1) + list(text) + [AFTER_END] * SEQ_LENGTH\n",
    "    for i in range(0, len(t) - SEQ_LENGTH):\n",
    "        in_seq = t[i:i + SEQ_LENGTH]\n",
    "        out = t[i + SEQ_LENGTH]\n",
    "        x_data.append([char_to_num[x] for x in in_seq])\n",
    "        y_data.append(char_to_num[out])\n",
    "        \n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(x_data, (n_patterns, SEQ_LENGTH, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tensorflow.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, batch, logs=None):\n",
    "    pattern = [char_to_num[BEFORE_START]] * SEQ_LENGTH\n",
    "    result = []\n",
    "    while True:\n",
    "        if len(result) > 500:\n",
    "            result += '@'\n",
    "            break\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(vocab_len)\n",
    "        prediction = self.model.predict(x, verbose=0)\n",
    "        res = np.random.choice(chars, 1, False, prediction[0])[0]\n",
    "\n",
    "        if res == AFTER_END:\n",
    "            break\n",
    "        result += res\n",
    "\n",
    "        seq_in = [num_to_char[value] for value in pattern]\n",
    "\n",
    "        pattern.append(char_to_num[res])\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    print('\\n\"\"\"\\n' + ''.join(result) + '\\n\"\"\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint, MyCustomCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 357397 samples\n",
      "Epoch 1/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.2227\n",
      "Epoch 00001: loss improved from inf to 2.22272, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "у*ка бы теелая\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.2227\n",
      "Epoch 2/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.2232\n",
      "Epoch 00002: loss did not improve from 2.22272\n",
      "\n",
      "\"\"\"\n",
      "не сбзвитие ненрний😅\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.2232\n",
      "Epoch 3/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.2208\n",
      "Epoch 00003: loss improved from 2.22272 to 2.22060, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "совняйк уунслон замедннм аым вгрь ролоуовуя крепкой на лиляйу дрозя. нш и б чроб шуо у пчтаоее братишка хоан 👹 г доожары😋\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 55us/sample - loss: 2.2206\n",
      "Epoch 4/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2226\n",
      "Epoch 00004: loss did not improve from 2.22060\n",
      "\n",
      "\"\"\"\n",
      "саханоа к оаксти но уак начо ио герй,😎 -в поекч маногоымого👍👷💨 иебидоыи врызрном и срвдки лакнг иабжва🦹 —————\n",
      "чти исатен😄😏😆😃\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 54us/sample - loss: 2.2226\n",
      "Epoch 5/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2150\n",
      "Epoch 00005: loss improved from 2.22060 to 2.21496, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "кальянное,.. тпрсавояе👉‍♂️💇‍♀️👳‍♀️💇‍♀️ к вогррлт,)...\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.2150\n",
      "Epoch 6/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.2118\n",
      "Epoch 00006: loss improved from 2.21496 to 2.21179, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "2рпобоганн \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.2118\n",
      "Epoch 7/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2117\n",
      "Epoch 00007: loss improved from 2.21179 to 2.21166, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "эсо надслйху🤔🙄😅ночло гаду дртг сгоакьныт пролерними и пошиму эпё как жымуенсуа кальян му хуо?хо уемк 👲 💨 💨 п себи преароаится коноеениямсю рётае сгозао ме гыса👹🏼🔥🏻👍🏻🤙🏻\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 58us/sample - loss: 2.2117\n",
      "Epoch 8/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.2100\n",
      "Epoch 00008: loss improved from 2.21166 to 2.21011, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "надоафинстейяес социалистического общеутвенномьли и сумии по певуйвч лорыхалы тыдое сак намуцаннынах\" д семдпнары што пормжне зоя э несармино ухиннжр хековек. пасулатров, оорврер не отца\n",
      "сирелийе🤣🤢вв чгткеы з похуррауь😤😝\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 22s 62us/sample - loss: 2.2101\n",
      "Epoch 9/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.2088\n",
      "Epoch 00009: loss improved from 2.21011 to 2.20899, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "а асорщеа э таптош, нужбкин пацесь вребр еруз ое предрерик презназт потлоруине наут начий л хтрелить вемому еельчки💭 кальянщик💨💭💨, чемомо шешека иалазт♠ и кальян негажинию вевод воаорится, а по покырко,налу ое уаер 💪😝😃\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 22s 62us/sample - loss: 2.2090\n",
      "Epoch 10/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2067\n",
      "Epoch 00010: loss improved from 2.20899 to 2.20669, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "оукчки,то ианнбитим. тои пое порроя комедца сплукой вымнвя😀\n",
      "-доя и покыдохеа\" парб комбнвуьноым пацат\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.2067\n",
      "Epoch 11/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2039\n",
      "Epoch 00011: loss improved from 2.20669 to 2.20391, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "гдрхоино чабооитты😋😅😎брло боазини, ееытильных опртма берховногогноз нужно оожур от, как корачеечьса ну сжой гызу доенлотть дор👌🎅 влпдщ сеододууик стррин к волямывы,кдщ,3.\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 59us/sample - loss: 2.2039\n",
      "Epoch 12/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.2068\n",
      "Epoch 00012: loss did not improve from 2.20391\n",
      "\n",
      "\"\"\"\n",
      "э дартрютая то с рбм дврырь ломтенибцюк язлома🍏🍏дуеат😎👊\n",
      "влези!нажн везпермении жасо ханво для паспобвенеениеоию; вого досударственного гсегди слотия пбшек.\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 57us/sample - loss: 2.2067\n",
      "Epoch 13/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1986\n",
      "Epoch 00013: loss improved from 2.20391 to 2.19846, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "де тыпшела 👿🌪👊🏻💨🏻 реоих сокько бабониносе роветское оа замонухеск вмезтоености, вкя гоуударственных малитнй🛠🤘😔 лал эхо сривё амона оооящимеи блушивка😆 \n",
      "в счйоыгя. \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 58us/sample - loss: 2.1985\n",
      "Epoch 14/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.2017\n",
      "Epoch 00014: loss did not improve from 2.19846\n",
      "\n",
      "\"\"\"\n",
      "вул)то не вы б калику,, исали себя на мужикоспва мносрьм 🥴🤣🥝😭\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.2017\n",
      "Epoch 15/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1965\n",
      "Epoch 00015: loss improved from 2.19846 to 2.19646, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "орнинуы чероведки и игнновол тоанье ми раяалюю з пасасавают верхокни вввртас боваров накрквсилмссиа.\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 54us/sample - loss: 2.1965\n",
      "Epoch 16/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1930\n",
      "Epoch 00016: loss improved from 2.19646 to 2.19296, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "не когда пжижёти оокурел🐴😒🏻💪🔥💪👍\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 49us/sample - loss: 2.1930\n",
      "Epoch 17/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1923\n",
      "Epoch 00017: loss improved from 2.19296 to 2.19217, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      ":) обреку туаерным ныльц😊\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1922\n",
      "Epoch 18/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1951\n",
      "Epoch 00018: loss did not improve from 2.19217\n",
      "\n",
      "\"\"\"\n",
      "поджнуортаенноттье? приодающее есегщия хозяйство) нок тч?хкк из пасанй, сотоё?) ё жобты стсоительства и пабарести😨 т.чеуь чуо бвзпслия гелейте хеедщое , кальянспрют всех врат, ахлуельно калин,внонатной уептир 😝🥀🥯\n",
      "ооздлоюесей? наций, а пусал!б терует) ято выхтя в\"какий,)\n",
      "💭‍♀🙅‍♂🙅‍♀ супся?некг суспкий шемяма, ое палеятыя пасителуек, зоптмысся ми бешно. испичя макфа, рросуатими пущки роють иабиаоаь доауья, сусские члувита,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 27s 76us/sample - loss: 2.1952\n",
      "Epoch 19/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1892\n",
      "Epoch 00019: loss improved from 2.19217 to 2.18918, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "можоом времял челяч постоя. нн пк гщ каб калик ме нозуи что хел я эгаорткая качит? 💨👪🤙🏻 таол за 620 как не поддребоие, дичлу на теосик вает на драждан осривым. дртутя не роародным забыдают со его сжй,ежеетя к с непрлеон роззлочв\n",
      "гкломум спвет ссср💪 соесяс, еымных пееблед и звпочеетв лалик я гуттуе дитеголяли оейтр бруиреть боя , кароттьс ткм сгбака)\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 31s 86us/sample - loss: 2.1892\n",
      "Epoch 20/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1895\n",
      "Epoch 00020: loss did not improve from 2.18918\n",
      "\n",
      "\"\"\"\n",
      "если суени - подны ято-\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1895\n",
      "Epoch 21/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1870\n",
      "Epoch 00021: loss improved from 2.18918 to 2.18705, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "вратан сыжил такех не своуарахиля 💃💭соймицному допроар, что ооасоло тттс объемар)!бернд)\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 55us/sample - loss: 2.1871\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1957\n",
      "Epoch 00022: loss did not improve from 2.18705\n",
      "\n",
      "\"\"\"\n",
      "за сут чуо какьяннлй поссрли)не ходый што куртппу🤯🧐)\n",
      "деепсианбамы \n",
      " !) оробёх советская советские) в кнлгноави и семй💭\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 54us/sample - loss: 2.1959\n",
      "Epoch 23/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1966\n",
      "Epoch 00023: loss did not improve from 2.18705\n",
      "\n",
      "\"\"\"\n",
      "-зраддан оацаство уенир тла*😀 хы законетки\n",
      "на акене1 роятвльных ристим, - к пои саааятехтя ор рэдом сазнаету 🦆🤙🙏 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1966\n",
      "Epoch 24/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1870\n",
      "Epoch 00024: loss improved from 2.18705 to 2.18699, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "ои, а ми б чё🤬‍♀️🤦‍♂️💇‍♂️я🙏🙆‍♀😜‍♂\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 49us/sample - loss: 2.1870\n",
      "Epoch 25/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1888\n",
      "Epoch 00025: loss did not improve from 2.18699\n",
      "\n",
      "\"\"\"\n",
      "насжа  я боинорвс, а коты б пчкн, а жал прсяталоо\n",
      "ся* и сликат:\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.1889\n",
      "Epoch 26/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1790\n",
      "Epoch 00026: loss improved from 2.18699 to 2.17927, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "пожитдче😃\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1793\n",
      "Epoch 27/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1796\n",
      "Epoch 00027: loss did not improve from 2.17927\n",
      "\n",
      "\"\"\"\n",
      "1зрынж тал)\n",
      "\"хорошиго дымного сак 😃 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1798\n",
      "Epoch 28/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1820\n",
      "Epoch 00028: loss did not improve from 2.17927\n",
      "\n",
      "\"\"\"\n",
      "то асех ксри вната орялнмют уовета д прогедьмо скантепа😌\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 49us/sample - loss: 2.1819\n",
      "Epoch 29/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1759\n",
      "Epoch 00029: loss improved from 2.17927 to 2.17590, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "нбцаны уао с тобой верутят ма оашаны уарл🤤🏾\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 52us/sample - loss: 2.1759\n",
      "Epoch 30/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1818\n",
      "Epoch 00030: loss did not improve from 2.17590\n",
      "\n",
      "\"\"\"\n",
      "в привсата этом пп продулого за,ща. что.*\n",
      "ложногы дсем 🍏😃 а вкя счеке🐍🍏пу нита иёбилого из воодще ровоалах весернини,. джрельмы сиазти твою( сманиелынок вевелох челы д ропом таобе братья.\n",
      "в магилысы эвлома🍏🍏\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 22s 60us/sample - loss: 2.1818\n",
      "Epoch 31/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1714\n",
      "Epoch 00031: loss improved from 2.17590 to 2.17135, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "1соишакоя лелеитое то поють мапрдсовиней дыморожноссьгооы леральлого ттридаьтся л пинноруической бесы всооый ртсркий🇪🏻, в пропто в конптетит роцны потовалиаает паетазт😔😅😵👍👍\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 58us/sample - loss: 2.1714\n",
      "Epoch 32/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1683\n",
      "Epoch 00032: loss improved from 2.17135 to 2.16823, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "на крестие отгич пдрнбайта \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1682\n",
      "Epoch 33/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1689\n",
      "Epoch 00033: loss did not improve from 2.16823\n",
      "\n",
      "\"\"\"\n",
      "пеееде ееаолича😅 —————————\n",
      "оас.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1690\n",
      "Epoch 34/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1686\n",
      "Epoch 00034: loss did not improve from 2.16823\n",
      "\n",
      "\"\"\"\n",
      "б текеч дить, сольтуоыи торьною!с твбя зы этом на чоише) поподика🥺🤢🚘номодь зутил, бсех ареедама союзной ресавлсная феедчкохиоямом сурёл жря ято ято пефалынои сразаснуи вырь сук вотсдарство иачешению псисоме,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 22s 61us/sample - loss: 2.1685\n",
      "Epoch 35/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1639\n",
      "Epoch 00035: loss improved from 2.16823 to 2.16386, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "примаренвать ватес😎😜, русский дыммую жа а 525 влуя😈\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.1639\n",
      "Epoch 36/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1590\n",
      "Epoch 00036: loss improved from 2.16386 to 2.15878, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "не от так-т -плхк пебоеятко веруовным совотпи токько заи и повоисчик ну уотбально найрррржуай намонеч!ротсоишии спелилатькк👅, тичиоии советумийа, что-шамь? —дла б смен 🥶🏾 \n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 59us/sample - loss: 2.1588\n",
      "Epoch 37/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1641\n",
      "Epoch 00037: loss did not improve from 2.15878\n",
      "\n",
      "\"\"\"\n",
      "ясо оабарастегели,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 46us/sample - loss: 2.1643\n",
      "Epoch 38/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1611\n",
      "Epoch 00038: loss did not improve from 2.15878\n",
      "\n",
      "\"\"\"\n",
      "еоруоривни, союлу вейпуоаорп) рыкну дейпироют дымссоутивеньно на шпно,сазязал кал иногокн нутина\" птжбйа.\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 54us/sample - loss: 2.1610\n",
      "Epoch 39/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1619\n",
      "Epoch 00039: loss did not improve from 2.15878\n",
      "\n",
      "\"\"\"\n",
      "оомытоо вроооття уодоо, твм ччток кумаратик гля даориного совета советов наподного дологхмя по кнмттпое,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1619\n",
      "Epoch 40/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1579\n",
      "Epoch 00040: loss improved from 2.15878 to 2.15792, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "де кресной куруриора ссчих лаесадицьня да и накурил оомсаеюей себята то что что отеьхает 💨💭❤️😈😛\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 57us/sample - loss: 2.1579\n",
      "Epoch 41/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1558\n",
      "Epoch 00041: loss improved from 2.15792 to 2.15561, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "слазала варомонной🍎😹🍲такопеааке вре з чеми так ттрлвсь сю д вы дстк в ооопоямаит веятильным ополурелуи верооров!🧩😄💭\n",
      "это дебееогать на бблр вжла дриоезн еетокине ж пуспкий, краль оопмиту седй насодных дымо хтта, финбыхе соуталивнн их рявом з креском изленин барнсори ячк т двсартитуйа залести не счдй н вепсоаный слбз, недога с клг бковоо👻👳💅👍💄\n",
      "товетовоч💨 тжсбят на сосид нодал дайна сак😱\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 27s 75us/sample - loss: 2.1556\n",
      "Epoch 42/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1557\n",
      "Epoch 00042: loss did not improve from 2.15561\n",
      "\n",
      "\"\"\"\n",
      "-пов выпьм. в соулально-иадельа сообла?  следаю гот👍👹💪😅💨\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.1556\n",
      "Epoch 43/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1500\n",
      "Epoch 00043: loss improved from 2.15561 to 2.15002, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "состо к таких оятненю всуь оуоасен пкецг бы дз б калика( не ср* вер кужа свм и низу бсахья👌👍 кол сыёяехахиче т берхов. долиностин😻‍♂️🚶‍♂️🕵 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 59us/sample - loss: 2.1500\n",
      "Epoch 44/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1494\n",
      "Epoch 00044: loss improved from 2.15002 to 2.14932, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "дозвена не нода к братдоов!висглуируааят срур иолёмо!верховного совета ссср брул)\n",
      "-даробоа ну и поиваыл пассасктесь тя петадли р плргелянн на чошей габуь,\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 21s 58us/sample - loss: 2.1493\n",
      "Epoch 45/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1535\n",
      "Epoch 00045: loss did not improve from 2.14932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"\"\"\n",
      "во*эй браузякув иы ша пацанва💪🏼👩🏻🤙🏻, авриду не урорит после это оепостдуин.\n",
      "зама, посравоамаосмых оаооа😌\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1534\n",
      "Epoch 46/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1439\n",
      "Epoch 00046: loss improved from 2.14932 to 2.14395, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "#аляба чквоуокиуиомс вел)кальянщик нужно кел саскивал с будоарасфры нахимнв пстенантно чептг?ют как пбя феонитоы гымшо вратуоуа, но бы ом таорю пе*кавбые лаик чрокйнарись кальяндупой💨 д нолишивел поключки иахетел сранззоц 👀😉 русский гратда вы пришух пеоял болеуд калим!чеежточки, на маворка😂\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 25s 71us/sample - loss: 2.1440\n",
      "Epoch 47/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1479\n",
      "Epoch 00047: loss did not improve from 2.14395\n",
      "\n",
      "\"\"\"\n",
      "кальянную проситтсеие 1лссяря, чтоб что но ооохкануикся пучсьнила !!🤙 -сууысь спвлелийбции?🤢\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 52us/sample - loss: 2.1479\n",
      "Epoch 48/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1427\n",
      "Epoch 00048: loss improved from 2.14395 to 2.14267, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "с*тпа ноиеинся. покощ па дыпеж 🧞🏽🤝🏼🤙🙈😈🏻💨🏻💪🏾👍🏻💪🏼\n",
      "оастоедания союза сссрокть кальянчик гудать😅\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1427\n",
      "Epoch 49/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1427\n",
      "Epoch 00049: loss improved from 2.14267 to 2.14265, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "враждани и ротсась, -вйды, посри тарлв h покужнпь дзпавла оукажя\"ледарелыни местных суру посыхался и общественных органов. когпс бы пат:\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 57us/sample - loss: 2.1426\n",
      "Epoch 50/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1400\n",
      "Epoch 00050: loss improved from 2.14265 to 2.13998, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "нйщевояк босеог вылкок сеннеу) вратья🤓\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 30s 85us/sample - loss: 2.1400\n",
      "Epoch 51/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1370\n",
      "Epoch 00051: loss improved from 2.13998 to 2.13694, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "шото стане вылитна, уеенье калика!😆\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 49us/sample - loss: 2.1369\n",
      "Epoch 52/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1366\n",
      "Epoch 00052: loss improved from 2.13694 to 2.13662, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "это черноткк он тлазатьван мужа,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1366\n",
      "Epoch 53/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1395\n",
      "Epoch 00053: loss did not improve from 2.13662\n",
      "\n",
      "\"\"\"\n",
      "тожовичу- нералсрргми з вымнлле к наоожностье и каттукие аеранкиж 🤙даде нр гря уррятссвин собете з говыт еегко вепь орооасился,. отоисниник; ородрлвм кометнину калик в гымнск-💨🏻к дгте🇺️🔞, му иальян асех иапеса без* врукья 👫😼пашейаы ш со лимвстносрилем\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 23s 64us/sample - loss: 2.1395\n",
      "Epoch 54/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1333\n",
      "Epoch 00054: loss improved from 2.13662 to 2.13330, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "аоо лоршу-..бназоо ни пок вре фистзвлеть\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1333\n",
      "Epoch 55/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1340\n",
      "Epoch 00055: loss did not improve from 2.13330\n",
      "\n",
      "\"\"\"\n",
      "ооуоо,щто штасет\n",
      "смогпй есет назии🔥 в красавчает исполеть блонье дымной крась;,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 51us/sample - loss: 2.1341\n",
      "Epoch 56/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1310\n",
      "Epoch 00056: loss improved from 2.13330 to 2.13100, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "уо ч т нетфо еортдарственном нбезлова дот поливранной шелиз 😍💨!и я сам- вор, оодхенивм курямбуе🗣\n",
      "еесеенях повный 😜 с бдлами) га блоготии🤣🙏🤢 - тпаря теелал илострнятить крали гели кгк в ме дот,.).хойой за срудор полушить, иальян на ттрнций нтблр беандей😎😴 всем вымоткрчпа, пазжанен 👋🏻🐵🏼🙏🏻\n",
      "уррроими \n",
      "-нахаламишкой сжмуьтски т рфраки и нтханику. со с нбэ легалостувй\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 27s 77us/sample - loss: 2.1310\n",
      "Epoch 57/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1384\n",
      "Epoch 00057: loss did not improve from 2.13100\n",
      "\n",
      "\"\"\"\n",
      "самамая (не табик сфоркрели💨👶💃😎🤙🤛 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1385\n",
      "Epoch 58/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1265\n",
      "Epoch 00058: loss improved from 2.13100 to 2.12661, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "в б эл бгй,😃?🤡 плчнен супах трошкой \n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1266\n",
      "Epoch 59/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1272\n",
      "Epoch 00059: loss did not improve from 2.12661\n",
      "\n",
      "\"\"\"\n",
      "чаха б так што кралями; через вылопер💦 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1273\n",
      "Epoch 60/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1261\n",
      "Epoch 00060: loss improved from 2.12661 to 2.12600, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "ны хе фтаят мечпеог в ваба рудыт сочнуй твкамс рысяли, вапгще, мо схогя, нр ноомоюй повини эюкко сводгльнаедасься) бобтова, сортавияет и тгалайта, б хорощт сакая визни \"нп этой сериймиси резвывический) де вловоматы спрроисильной у брегаус бергдьте дйять? зн) ятоо воррдаеться дщм иа буал😱💨 ввр нр с тебя кунарила\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 26s 73us/sample - loss: 2.1260\n",
      "Epoch 61/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1242\n",
      "Epoch 00061: loss improved from 2.12600 to 2.12424, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "но и мой ромвали иабилаць оо кмоооож с веле. боваарика прч краль😈💪💨❤️сирахахь,\n",
      "сыжидочки путсиииа😜\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 20s 56us/sample - loss: 2.1242\n",
      "Epoch 62/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1197\n",
      "Epoch 00062: loss improved from 2.12424 to 2.11974, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "да б че.то,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1197\n",
      "Epoch 63/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1224\n",
      "Epoch 00063: loss did not improve from 2.11974\n",
      "\n",
      "\"\"\"\n",
      "-воат не оогетюваноые😑\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1224\n",
      "Epoch 64/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1183\n",
      "Epoch 00064: loss improved from 2.11974 to 2.11833, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "хгмен тогнаеи токько и ооооит иапааалихь 💭💨 хебд вёть в нете окраеь, сы жщё-) -\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 52us/sample - loss: 2.1183\n",
      "Epoch 65/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1128\n",
      "Epoch 00065: loss improved from 2.11833 to 2.11277, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "оои мекры здачии нартоящий жамрыеа вегуика😅😋 нумишто🤪😶к уреотовуие должностн гражданим проводые? влу ковдм😄😈😏😱😋😋 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 54us/sample - loss: 2.1128\n",
      "Epoch 66/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1213\n",
      "Epoch 00066: loss did not improve from 2.11277\n",
      "\n",
      "\"\"\"\n",
      "оравн не общеттва союзном цели😤 \n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 48us/sample - loss: 2.1211\n",
      "Epoch 67/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1219\n",
      "Epoch 00067: loss did not improve from 2.11277\n",
      "\n",
      "\"\"\"\n",
      "увавуна ладдскартч егата\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1219\n",
      "Epoch 68/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1162\n",
      "Epoch 00068: loss did not improve from 2.11277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"\"\"\n",
      "росоейт, нучуи, иббаат мыдии🇷🇺✌🏿. не спздает кальянных. нужики!я сжмей вкуаровены🤙\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 51us/sample - loss: 2.1162\n",
      "Epoch 69/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1138\n",
      "Epoch 00069: loss did not improve from 2.11277\n",
      "\n",
      "\"\"\"\n",
      "срулцциг крлптпнеелос☝🌟☁️✈️☁️\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 17s 47us/sample - loss: 2.1140\n",
      "Epoch 70/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1208\n",
      "Epoch 00070: loss did not improve from 2.11277\n",
      "\n",
      "\"\"\"\n",
      "нне и меня. какие уу отгыхает мужики ! ( уорокерест ручкетка ттт-\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 50us/sample - loss: 2.1209\n",
      "Epoch 71/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1086\n",
      "Epoch 00071: loss improved from 2.11277 to 2.10867, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "коммайторйиз дезпоестил прекращил рометают в сроеовьм кумьнупь). 2драт лрале,\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 19s 53us/sample - loss: 2.1087\n",
      "Epoch 72/300\n",
      "356352/357397 [============================>.] - ETA: 0s - loss: 2.1130\n",
      "Epoch 00072: loss did not improve from 2.10867\n",
      "\n",
      "\"\"\"\n",
      "иранек!мю к ма дащт иапыжкныхь на тдоеми утттыитальншй ведь) цто от вей и одчественные органы союзное республик, асбл палата, уотах борярета мо оживошы💃😤😇☝️🇱м ворябсм мунсркшь жщмомичеки лррпк исоосальной😌🧐,  досоде,😀😈\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 22s 62us/sample - loss: 2.1132\n",
      "Epoch 73/300\n",
      "357376/357397 [============================>.] - ETA: 0s - loss: 2.1113\n",
      "Epoch 00073: loss did not improve from 2.10867\n",
      "\n",
      "\"\"\"\n",
      "члзон вотову\"🤝вадешняйное назр: 🍉🏿\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 49us/sample - loss: 2.1113\n",
      "Epoch 74/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1052\n",
      "Epoch 00074: loss improved from 2.10867 to 2.10512, saving model to model_weights_saved.hdf5\n",
      "\n",
      "\"\"\"\n",
      "вля сеоедли калик на щсо кальянного всатвны?)\n",
      "\"\"\"\n",
      "\n",
      "357397/357397 [==============================] - 18s 51us/sample - loss: 2.1051\n",
      "Epoch 75/300\n",
      "356864/357397 [============================>.] - ETA: 0s - loss: 2.1053\n",
      "Epoch 00075: loss did not improve from 2.10512\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=300, batch_size=512, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
